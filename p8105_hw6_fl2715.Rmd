---
title: "p8105_hw6_fl2715"
author: "Fengwei Lei"
output: github_document
---

## Load Library and Set Seed
```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(p8105.datasets)
library(patchwork)
library(forcats)
library(modelr)
library(mgcv)
set.seed(1)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Problem 1

Firstï¼Œ we load the data.
```{r,message = FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31")  |> 
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10)  |> 
  select(name, id, everything())
```

After that, we take Bootstrap procedure with `modelr::bootstrap`.
```{r}
boot_results = weather_df  |> 
  modelr::bootstrap(n = 5000)  |> 
  mutate(
    model = map(strap, \(df) lm(tmax ~ tmin, data = df)),  
    glance_results = map(model, broom::glance),           
    tidy_results = map(model, broom::tidy)                
  )


final_results = boot_results |> 
  mutate(
    r_squared = map_dbl(glance_results, "r.squared"),  
    tidy_df = map(tidy_results, \(df) df |> 
                    select(term, estimate) |>         
                    pivot_wider(names_from = term, values_from = estimate) |> 
                    mutate(log_beta = log(`(Intercept)`) + log(tmin))) 
  ) |> 
  select(-strap, -model, -glance_results, -tidy_results) |> 
  unnest(tidy_df)  
```

Then, using the results for bootstrap, we draw the distribution plots for the estimates $\hat{r}^2$ and $log(\hat{\beta}_0 * \hat{\beta}_1)$.
```{r}
p1 = ggplot(final_results, aes(x = r_squared)) +
  geom_density(fill = "blue", alpha = 0.5) +
  labs(title = "Distribution of R^2", x = "R^2", y = "Density") +
  theme_minimal()

p2 = ggplot(final_results, aes(x = log_beta)) +
  geom_density(fill = "red", alpha = 0.5) +
  labs(title = "Distribution of log(beta0 * beta1)", x = "log(beta0 * beta1)", y = "Density") +
  theme_minimal()

p1 + p2
```

**Description**:

From the above plots, we can see that these two estimates both nearly follow the normal distribution. The left plot shows the distribution of  $\hat{r}^2$  , concentrated between 0.88 and 0.94 with a symmetric unimodal shape. The right plot represents $log(\hat{\beta}_0 * \hat{\beta}_1)$ , concentrated between 1.95 and 2.10, also symmetric and unimodal, reflecting precise and stable estimates.


Using the 5000 bootstrap estimates, identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for $\hat{r}^2$ and $log(\hat{\beta}_0 * \hat{\beta}_1)$.
```{r}
ci_results = final_results |> 
  reframe(
    r_squared_ci = quantile(r_squared, c(0.025, 0.975)),
    log_beta_ci = quantile(log_beta, c(0.025, 0.975))
  )

cat("95% Confidence Interval for R^2:", ci_results$r_squared_ci, "\n")
cat("95% Confidence Interval for log(beta0 * beta1):", ci_results$log_beta_ci, "\n")
```

## Problem 2

First, we load the data.
```{r}
homicide_data = read_csv("data/homicide-data.csv") |>
  janitor::clean_names() |> 
  mutate(city_state = paste(city, state, sep = ", "),
         resolved = ifelse(disposition == "Closed by arrest", 1, 0),
         victim_race = str_to_lower(victim_race),
         victim_age_clean = as.numeric(gsub("[^0-9]", "", victim_age))) |> 
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("white", "black")
  ) |> 
  mutate(victim_age = victim_age_clean) |> 
  select(-victim_age_clean)  
```
Then, we run the logistic regression model. And we obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed.
```{r}
baltimore_data = homicide_data |> 
  filter(city_state == "Baltimore, MD")

baltimore_model = glm(resolved ~ victim_age + victim_sex + victim_race, 
                       data = baltimore_data, family = binomial())

baltimore_results = broom::tidy(baltimore_model, conf.int = TRUE, exponentiate = TRUE)

baltimore_or = baltimore_results |> 
  filter(term == "victim_sexMale") |> 
  select(term, estimate, conf.low, conf.high) |> 
  rename(
    `Comparison` = term,
    `Adjusted Odds Ratio` = estimate,
    `Lower 95% CI` = conf.low,
    `Upper 95% CI` = conf.high
  )

baltimore_or |> 
  knitr::kable(caption = "Adjusted Odds Ratio for Male vs Female Victims (Baltimore)") 
```

After that, we run `glm` for each of the cities.
```{r,warning = FALSE}
city_results = homicide_data |> 
  group_by(city) |> 
  nest() |> 
  mutate(
    models = map(data, \(df) glm(resolved ~ victim_age + victim_sex + victim_race, 
                             data = df, family = binomial())),
    tidy_results = map(models, \(model) broom::tidy(model, conf.int = TRUE, exponentiate = TRUE))
  ) |> 
  unnest(tidy_results) |> 
  filter(term == "victim_sexMale") |> 
  select(city, estimate, conf.low, conf.high) 

city_results |> 
  knitr::kable(
    col.names = c(
      "City", 
      "Adjusted Odds Ratio", 
      "Lower 95% CI", 
      "Upper 95% CI"
    ),
    caption = "Adjusted Odds Ratio for Male vs Female Victims by City"
  )
```

Finally, we create a plot that shows the estimated ORs and CIs for each city.
```{r}
city_results |> 
  ggplot(aes(y = reorder(city, estimate), x = estimate)) + 
    geom_point(color = "blue") +
    geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0.25) +  
    labs(
      title = "Adjusted Odds Ratios for Solving Homicides (Male vs Female Victims)",
      x = "Adjusted Odds Ratio (95% CI)",
      y = "City"
    )
```

**Comments**:
This plot compares the likelihood of solving homicides involving male versus female victims in different cities. In most cities, cases with male victims are less likely to be solved (odds ratios below 1), with some cities like New York and Baton Rouge showing especially low chances for male victims. A few cities, like Albuquerque and Stockton, show higher chances for male cases. Wide error bars in some cities mean there is uncertainty in the data.


